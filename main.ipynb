{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28b978d0",
   "metadata": {},
   "source": [
    "# Kenyan Food Classification Training Pipeline (Trainer Version)\n",
    "This notebook demonstrates a modular neural network training pipeline using the scripts in the `trainer` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85afe8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.set_start_method(\"spawn\", force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d76736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Trainer imports\n",
    "from trainer.trainer import Trainer\n",
    "from trainer.metrics import AccuracyEstimator\n",
    "from trainer.configuration import SystemConfig, DatasetConfig, DataloaderConfig, OptimizerConfig, TrainerConfig\n",
    "from trainer.utils import setup_system, patch_configs\n",
    "\n",
    "from trainer.data_loader import get_data_loaders\n",
    "from trainer.model import get_model\n",
    "\n",
    "from trainer.tensorboard_visualizer import TensorBoardVisualizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a0b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizer (TensorBoard)\n",
    "visualizer = TensorBoardVisualizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba961141",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Set up all configuration objects for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b78fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "system_config = SystemConfig()\n",
    "setup_system(system_config)\n",
    "\n",
    "# Patch configs for device\n",
    "dataloader_config, trainer_config = patch_configs()#(epoch_num_to_set=80, \n",
    "                                                    #batch_size_to_set=16)  \n",
    "\n",
    "optimizer_config = OptimizerConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ddd19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataloader Config:\", dataloader_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38634b76",
   "metadata": {},
   "source": [
    "## Import Loaders and Model\n",
    "Import all the required components to start the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e577d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "\n",
    "#dataloader_config = DataloaderConfig()\n",
    "\n",
    "train_loader, val_loader, num_classes = get_data_loaders(\n",
    "    data_root=\"./data\", \n",
    "    batch_size=dataloader_config.batch_size, \n",
    "    num_workers=dataloader_config.num_workers, \n",
    "    seed=system_config.seed, \n",
    "    data_augmentation=True,\n",
    "    test_size=dataloader_config.test_size,\n",
    "    persistent_workers=dataloader_config.persistent_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e33c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = get_model(\n",
    "    num_classes = num_classes,\n",
    "    pretrained = True,\n",
    "    freeze_backbone = True,\n",
    "    trainable_layers = 2\n",
    ") \n",
    "\n",
    "model = model.to(trainer_config.device)\n",
    "\n",
    "# Save the model visualization\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(trainer_config.device)\n",
    "visualizer.add_model_graph(model, input_tensor=dummy_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e1e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optimizer, Scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), \n",
    "                        lr=optimizer_config.learning_rate,\n",
    "                        #momentum=optimizer_config.momentum, \n",
    "                        weight_decay=optimizer_config.weight_decay)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "                                      step_size=optimizer_config.scheduler_step_size, \n",
    "                                      gamma=optimizer_config.scheduler_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b8981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and metric\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "metric_fn = AccuracyEstimator(topk=(1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3051811f",
   "metadata": {},
   "source": [
    "## Training\n",
    "Run the Trainer pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c556e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"PID:\", os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3114ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    loader_train=train_loader,\n",
    "    loader_test=val_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    metric_fn=metric_fn,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=scheduler,\n",
    "    device=trainer_config.device,\n",
    "    model_saving_frequency=trainer_config.model_saving_frequency,\n",
    "    save_dir=trainer_config.model_dir,\n",
    "    model_name_prefix=\"kenyanfood_model\",\n",
    "    data_getter=lambda sample: sample[\"image\"],\n",
    "    target_getter=lambda sample: torch.tensor(sample[\"target\"]),\n",
    "    stage_progress=trainer_config.progress_bar,\n",
    "    visualizer=visualizer,\n",
    "    get_key_metric=lambda metric: metric[\"top1\"]\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   metrics = trainer.fit(trainer_config.epoch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bd050d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2154a1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close TensorBoard writer\n",
    "visualizer.close_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5ed976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize accuracy and loss from metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract metrics\n",
    "epochs = metrics['epoch']\n",
    "train_loss = metrics['train_loss']\n",
    "val_loss = metrics['test_loss']\n",
    "val_acc = [m['top1'] if isinstance(m, dict) and 'top1' in m else m for m in metrics['test_metric']]\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, train_loss, label='Train Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, val_acc, label='Validation Accuracy (Top-1)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Validation Accuracy over Epochs')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f90839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Export the trained model to ONNX format\n",
    "#onnx_path = \"kenyanfood_model.onnx\"\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save the trained model's state_dict\n",
    "model_save_path = f\"kenyanfood_model_{timestamp}.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model state_dict saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63138ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab83cefd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f5ac138",
   "metadata": {},
   "source": [
    "## Inference on Test Set and Submission File Creation\n",
    "Now we run inference on the test set and create a DataFrame with the image ids and predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a59bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "# Load test.csv\n",
    "test_csv = pd.read_csv('./data/test.csv')\n",
    "test_img_dir = './data/images/images'  # same as train\n",
    "\n",
    "# Get class_to_idx mapping from training set\n",
    "train_csv = pd.read_csv('./data/train.csv')\n",
    "classes = sorted(train_csv.iloc[:, 1].unique())\n",
    "class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "idx_to_class = {idx: cls for cls, idx in class_to_idx.items()}\n",
    "\n",
    "def test_transform(image):\n",
    "    # Use the same resize as validation\n",
    "    import albumentations\n",
    "    resize = albumentations.Compose([\n",
    "        albumentations.Resize(height=224, width=224)\n",
    "    ])\n",
    "    image = np.array(image)\n",
    "    image = resize(image=image)['image']\n",
    "    image = transforms.ToTensor()(image)\n",
    "    return image\n",
    "\n",
    "# Prepare test dataset\n",
    "image_ids = test_csv.iloc[:, 0].tolist()\n",
    "pred_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for img_id in tqdm(image_ids, desc=\"Predicting test set\"):\n",
    "        img_name = str(img_id)\n",
    "        if not img_name.lower().endswith('.jpg'):\n",
    "            img_name += '.jpg'\n",
    "        img_path = os.path.join(test_img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = test_transform(image)\n",
    "        image = image.unsqueeze(0).to(trainer_config.device)\n",
    "        output = model(image)\n",
    "        pred_idx = output.argmax(dim=1).item()\n",
    "        pred_label = idx_to_class[pred_idx]\n",
    "        pred_labels.append(pred_label)\n",
    "\n",
    "# Create DataFrame for submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': image_ids,\n",
    "    'label': pred_labels\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print('Saved predictions to submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e299cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv_pytorch (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
